##########################################################
##########################################################
###                                                    ###
###      Config file for runing iKAT experiments       ###
###                                                    ###
##########################################################
##########################################################

iterate:

# rewrites choices
  # P -> personalize, D -> demo, C -> cot, Re -> rel explain
  # O -> oracle, Rf -> rel feedback

  #retrieval_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs")
  #reranking_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___")
  #reranking_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___")
  #reranking_query_types=("rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rwrs" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___")
  # reranking_query_types=("rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rwrs")
  #retrieval_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs")
  #retrieval_query_types=("rar_personalized_cot1_rw" "rar_personalized_cotN_rw")
  #retrieval_query_types=("rar_rw_fuse_rar_personcot1_rw")
  # retrieval_query_types=("rar_rw_fuse_rar_rwrs")
  # reranking_query_types=("rar_personalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_rar_rw" "gpt-4o_rar_rwrs" "gpt-4o_rar_personalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_rar_rwrs_fuse_personalized_cot1_rw") 
  #retrieval_query_types=("round_robin_gpt-4o_3_lists")
  #retrieval_query_types=("personalize_level_3_lists_tune") 
  #retrieval_query_types=("gpt-4o_rar_rw" "gpt-4o_rar_rwrs" "gpt-4o_rar_personalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_judge_and_rewrite_optimize_mrr_non_normalize_test")
  #retrieval_query_type: ["gpt-4o_judge_and_rewrite_rwrs","gpt-4o_judge_and_rewrite_rs", "gpt-4o_rar_personalized_cot1_rs","gpt-4o_rar_personalized_cot1_rwrs", "gpt-4o_rar_rs" ]

  #retrieval_query_type: ["raw", "oracle"]
  #retrieval_query_type: ["gpt-4o_judge_and_rewrite_optimize_4_test"]
  # retrieval_query_type: [ "gpt-3.5_judge_and_rewrite_optimize_4_test"] 
  # retrieval_query_type: [
  #   "mistral_rar_rw",
  #   "mistral_rar_rwrs",
  #   "mistral_judge_and_rewrite_rw",
  #   "mistral_judge_and_rewrite_rwrs",
  #   "llama3.1_judge_and_rewrite_rw",
  #   "llama3.1_judge_and_rewrite_rwrs",
  #   "llama3.1_rar_rw",
  #   "llama3.1_rar_rwrs"
  # ]

  # topics: ["ikat_23_test","ikat_24_test"]
  # retrieval_query_type: [ 
  #   mistral_judge_and_rewrite_optimize_4_test,
  #   llama3.1_judge_and_rewrite_optimize_4_test,
  #   gpt-3.5_judge_and_rewrite_optimize_4_test,
  #   gpt-4o_judge_and_rewrite_optimize_4_test
  #   ] 
  # retrieval_model: ["splade_v3"] 
  # reranker: [none]
  # reranking_query_type: ["none"]
  
  # topics: ["ikat_23_test","ikat_24_test"]
  # retrieval_query_type: [ 
  #   oracle
  #   ] 
  # retrieval_model: ["splade_v3"] 
  # reranker: ["monot5_base_10k"]
  # reranking_query_type: ["oracle"]
  # fusion_type: ['none']

  # topics: ["ikat_24_test"]
  # retrieval_query_type: [ 
  #   "round_robin_3_lists",
  #   "gpt-4o_rar_rw+gpt-4o_rar_rwrs+gpt-4o_judge_and_rewrite_rw",
  #   "RRF_3_lists"
  #   ] 
  # retrieval_model: ["splade_v3"]
  # reranker: ["none"]
  # reranking_query_type: ["none"]

  # "gpt-4o_rar_manual_depersonalized_cot1_rw"
  # "gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw"

  # topics: ["ikat_23_test", "ikat_24_test"]
  # retrieval_query_type: [ 
  #   wo_explicit_level,
  #   wo_finegrianed,
  #   gpt-4o_judge_and_rewrite_optimize_4_test_no_normalize
  #   # gpt-4o_rar_manual_depersonalized_cot1_rw
  #   # gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw_optimize_4,
  #   # gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw,
  #   # gpt-4o_judge_and_rewrite_depers_rw,
  #   #gpt-4o_rar_rw_fuse_rar_rwrs_fuse_depers_jar_optimize_4
  #   ] 
  # retrieval_model: ["BM25"]
  # reranker: ["none"]
  # reranking_query_type: ["none"]

  # topics: ["ikat_23_test", "ikat_24_test"]
  # retrieval_query_type: ["gpt-4o_MQ4CS_mq_1", "gpt-4o_MQ4CS_mq_2"]
  # retrieval_model: ["BM25", "ance", "splade_v3"]
  # reranker: ["none"]
  # reranking_query_type: ["none"]
  # personalization_group: ["all"]
  # fusion_type: ["none"]

#   machine: ["octal30"]
#   topics: ["ikat_23_test", "ikat_24_test"]
#   retrieval_query_type: [
#     "MQ4CS_low_resource",
#     ours_low_resource,
#     ours_low_resource_100,
#     ours_low_resource_rerank2000,
#     ours_low_resource_rerank1000,
# ]
#   retrieval_model: ["ance"]
#   reranker: ["monot5_base_10k"]

  # machine: ["octal31"]
  # topics: ["ikat_23_test", "ikat_24_test"]
  # retrieval_query_type: [
  #   gpt-4o_jtr_wo_in_context_rw,
  #   gpt-4o_jtr_wo_cot_rw,
  #   wo_in_context,
  #   wo_cot
  # ]
  # retrieval_model: ["BM25","splade_v3"]
  # reranker: ["none"]
  # reranking_query_type: ["none"]

  # machine: ["octal31"]
  # topics: ["ikat_24_test"]
  # retrieval_query_type: [
  #   wo_finegrianed,
  #   wo_explicit_level,
  #   gpt-4o_judge_and_rewrite_optimize_4_test_no_normalize
  # ]
  # retrieval_model: ["BM25"]
  # reranker: ["none"]
  # reranking_query_type: ["none"]

#   machine: ["octal31"]
#   retrieval_model: ["BM25","splade_v3","ance"]
#   topics: ["ikat_23_test", "ikat_24_test"]
#   retrieval_query_type: [
#     "gpt-4o_MQ4CS_mq_3_1",
#     "gpt-4o_MQ4CS_mq_3_2",
#     "gpt-4o_MQ4CS_mq_3_3",
#     "MQ4CS_low_resource_3",
#     #"gpt-4o_MQ4CS_persq_rw"
# ]

#   machine: ["octal31"]
#   retrieval_model: ["BM25"]
#   topics: ["ikat_23_test", "ikat_24_test"]
#   retrieval_query_type: [
#     #"gpt-4o_MQ4CS_persq_rw"
#     "MQ4CS_low_resource_3_RRF",
#     "MQ4CS_low_resource_3_Round_Robin",
#     "MQ4CS_low_resource_3_grid_search"
# ]

  machine: ["octal31"]
  retrieval_model: ["splade_v3"]
  reranker: ["none"]
  topics: ["ikat_23_test", "ikat_24_test"]
  retrieval_query_type: [
    # "gpt-4o_GtR_mq_3_1",
    # "gpt-4o_GtR_mq_3_2",
    # "gpt-4o_GtR_mq_3_3",
    # "gpt-4o_GtR_low_resource_3_Round_Robin",
    # "gpt-4o_GtR_low_resource_3_RRF",
    # gpt-4o_judge_and_rewrite_optimize_retrieval_score
    #"gpt-4o_GtR_low_resource_3"
    # "gpt-3.5_MQ4CS_persq_rw",
    # "llama3.1_MQ4CS_persq_rw",
    # "mistral_MQ4CS_persq_rw"
    result_topic_entropy
]

param_mapping:
  machine:
    octal31:
      sparse_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_official_sparse_index/"  # Use local disk index for fastest access
      splade_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_splade_v3"  # Splade index path
      dense_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_ance_merged_2"  
    octal30:
      sparse_index_dir_path: "/part/02/Tmp/yuchen/indexes/clueweb22b_ikat23_official_sparse_index/"  # Use local disk index for fastest access
      splade_index_dir_path: "/part/02/Tmp/yuchen/indexes/clueweb22b_ikat23_splade_v3"  # Splade index path
      dense_index_dir_path: "/part/02/Tmp/yuchen/indexes/clueweb22b_ikat23_ance_merged_2"  

  reranker:
    monot5_base_10k:
      rerank_batch_size: 67
    monot5_large_10k:
      rerank_batch_size: 50
    monot5_3b_10k:
      rerank_batch_size: 10
    rankllama:
      rerank_batch_size: 10

  topics:
    ikat_24_test:
      input_query_path: "../data/topics/ikat24/ikat_2024_test.json"
      qrel_file_path: "../data/qrels/ikat_24_qrel.txt"
    ikat_23_test:
      input_query_path: "../data/topics/ikat23/ikat_2023_test.json"
      qrel_file_path: "../data/qrels/ikat_23_qrel.txt"

  retrieval_query_type:

    random_weights:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'random_weights'

    DEPS:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'pre_calculated'

    result_topic_entropy:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'pre_calculated'

    MQ4CS_low_resource:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_1, 
        gpt-4o_MQ4CS_mq_2
        ]
      personalization_group: "all"
      retrieval_top_k: 2000
      rerank_top_k: 2000
      reranking_query_type: "gpt-4o_MQ4CS_persq_rw"
      fusion_type: 'concat'
      reranker: "monot5_base_10k"

    gpt-4o_judge_and_rewrite_optimize_retrieval_score:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "retrieval_score"

    gpt-4o_GtR_low_resource_3_Round_Robin:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      fusion_type: 'round_robin'

    gpt-4o_GtR_low_resource_3_grid_search:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      fusion_type: 'per_query_personalize_level'
      optimize_level_weights: "no_level" 

    gpt-4o_GtR_low_resource_3_RRF:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      fusion_type: 'RRF'

    gpt-4o_GtR_low_resource_3:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      retrieval_top_k: 3000
      rerank_top_k: 3000
      reranking_query_type: "gpt-4o_MQ4CS_persq_rw"
      fusion_type: 'round_robin'
      reranker: "monot5_base_10k"

    MQ4CS_low_resource_3_Round_Robin:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      fusion_type: 'round_robin'

    MQ4CS_low_resource_3_RRF:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      fusion_type: 'RRF'

    MQ4CS_low_resource_3_grid_search:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      fusion_type: 'per_query_personalize_level'
      optimize_level_weights: "no_level" 

    MQ4CS_low_resource_3:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      retrieval_top_k: 3000
      rerank_top_k: 3000
      reranking_query_type: "gpt-4o_MQ4CS_persq_rw"
      fusion_type: 'concat'
      reranker: "monot5_base_10k"

    ours_low_resource:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 1000
      rerank_top_k: 50
      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    ours_low_resource_100:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 1000
      rerank_top_k: 100
      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    ours_low_resource_rerank2000:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 2000
      rerank_top_k: 2000

      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    ours_low_resource_rerank1000:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 1000
      rerank_top_k: 1000

      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_depers_jar_optimize_4:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_depers_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw_optimize_4:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_rar_manual_depersonalized_cot1_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_rar_manual_depersonalized_cot1_rw
        ]

      fusion_type: 'linear_weighted_score'
      fuse_weights: [0.1, 0.4]
      retrieval_model: "BM25"

    wo_cot:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_jtr_wo_cot_rw
        ]
      level_type: "gpt-4o_jtr_wo_cot" 
      fusion_type: 'per_query_personalize_level'
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    wo_in_context:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_jtr_wo_in_context_rw
        ]
      level_type: "gpt-4o_jtr_wo_in_context" 
      fusion_type: 'per_query_personalize_level'
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    wo_explicit_level:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'per_query_personalize_level'
      optimize_level_weights: "no_level" 
      fusion_normalization: "min-max"

    wo_finegrianed:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'linear_combination'
      fusion_normalization: "min-max"
      fuse_weights: [1,1,1]

    gpt-4o_judge_and_rewrite_optimize_4_test_no_normalize:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "none"
      optimize_level_weights: "group" 

    gpt-4o_judge_and_rewrite_optimize_4_test:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'none'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    RRF_3_lists:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'RRF'

    round_robin_3_lists:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'round_robin'

    2024_submission:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs,
        gpt-4o_rar_personalized_cot1_rw
        ]
      fusion_type: 'linear_weighted_score'
      fuse_weights: [0.1, 0.4]
      retrieval_model: "BM25"

    mistral_judge_and_rewrite_optimize_4_test : 
      QRs_to_rank: [
        mistral_rar_rw, 
        mistral_rar_rwrs, 
        mistral_judge_and_rewrite_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "mistral_judge_and_rewrite"
    llama3.1_judge_and_rewrite_optimize_4_test : 
      QRs_to_rank: [
        llama3.1_rar_rw, 
        llama3.1_rar_rwrs, 
        llama3.1_judge_and_rewrite_rw
      ]
      fusion_type: 'per_query_personalize_level'
      level_type: "llama3.1_judge_and_rewrite"
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.4]
      fusion_type: 'linear_combination'
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [1, 0.1]
    gpt-4o_rar_rw_fuse_rar_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs]
      fuse_weights: [1, 0.1]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [0.1, 0.4]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [0.1, 0.1]
    gpt-4o_judge_and_rewrite_rw_fuse_rwrs:
      QRs_to_rank: [gpt-4o_judge_and_rewrite_rw, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [0.4, 0.1]
    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.1, 0.4]
    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [1, 0.1, 0.1]
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.1, 0.4]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [0.1, 0.1, 0.4] 
    

fixed:
  ###############################################
  ## General
  ###############################################
  collection: "ClueWeb_ikat"  # Dataset collection
  topics: "ikat_23_test"  # Test topics
  input_query_path: "../data/topics/ikat23/ikat_2023_test.json"  # Path to input query file

  # use /part/02 for octal30, /part/01 for octal31
  # index_dir_path="/part/02/Tmp/yuchen/clueweb22b_ikat23_fengran_sparse_index_2/" # Please use local disk index to achieve the fastest access
  sparse_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_official_sparse_index/"  # Use local disk index for fastest access
  output_dir_path: "../results"  # Path to save results
  qrel_file_path: "../data/qrels/ikat_23_qrel.txt"  # Qrel file path
  seed: 42  # Random seed for reproducibility

  save_results_to_object: true
  save_ranking_list: true
  run_rag: true
  run_eval: true

  ###############################################
  ## Retrieval
  ###############################################
  # can be :"none","BM25", "ance", "dpr", "splade_v3". If "none", read ranking list from given_ranking_list_path
  retrieval_model: "ance"  
  retrieval_top_k: 1000  
  # "a" "b" "c" "all"
  personalization_group: "all"
  query_gpu_id: 2  # GPU ID for query encoder
  query_encoder_batch_size: 200  # Batch size for query encoding

  ############# Splade ############
  splade_query_encoder_path: "/data/rech/huiyuche/huggingface/models--naver--splade-v3/snapshots/8291b13eb8f4e24cc745c542825f14eb87296879"  # Splade query encoder path
  splade_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_splade_v3"  # Splade index path

  ############# Dense  ############
  use_pyserini_dense_search: false
  dense_query_encoder_path: "/data/rech/huiyuche/huggingface/models--castorini--ance-msmarco-passage/snapshots/6d7e7d6b6c59dd691671f280bc74edb4297f8234"  
  dense_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_ance_merged_2"  
  faiss_n_gpu: 4  # Number of GPUs for FAISS
  use_gpu_for_faiss: true
  embed_dim: 768  # Embedding dimension
  tempmem: -1  # Temporary memory setting
  passage_block_num: 12  # 116 for ikat

  ############# BM25 ############
  bm25_k1: 0.9  
  bm25_b: 0.4  

  ############# QE ############
  qe_type: "none"  
  fb_terms: 20  
  fb_docs: 10  
  original_query_weight: 0.5  

  ###############################################
  ## Fusion
  ###############################################
  #'none' 'round_robin', 'lienar_combination' 'linear_weighted_score' 'per_query_personalize_level'
  fusion_type: 'none'  
  #QRs_to_rank: ["gpt-4o_rar_rw", "gpt-4o_rar_rwrs", "gpt-4o_rar_personalized_cot1_rw"]
  QRs_to_rank: [
    "mistral_rar_rw", 
    "mistral_rar_rwrs",
    "mistral_judge_and_rewrite_rw"
    ]  
  fuse_weights: [0.1, 0.4]  
  # can be "none", "max", "min-max"
  fusion_normalization: "none"  
  # can be 'per_query_personalize_level', "gpt-4o_judge_and_rewrite","gpt-3.5_judge_and_rewrite"
  level_type: "gpt-3.5_judge_and_rewrite"  
  per_query_weight_max_value: 1.2  
  # can be 
  # (1) "no level", means finding the optimal weights for all ranking lists respectively 
  # (2) "2+1": first find the best weight for the 2 non-personalized query, then
  #   for the personalized query, perform optimization by group.
  # (3) "group": optimize by personalization level group
  optimize_level_weights: "group"  
  target_metrics: "mrr,ndcg@3,recall@10,recall@100"  
  optimize_step: 0.01  # Optimization step size

  ###############################################
  ## Reranking
  ###############################################
  # none, rankllama, rankgpt, monot5_base, monot5_base_10k, monot5_large, monot5_large_10k, monot5_3b, monot5_3b_10k,
  reranker: "none"  
  rerank_top_k: 50  
  cache_dir: "/data/rech/huiyuche/huggingface"  
  # on octal31: 67 for monot5_base, 10 for rankllama, 50 for monot5_large, 10 for t5_3b
  rerank_batch_size: 67  
  rerank_quant: "none"   # can be "none" ,"8b", "4b"
  rankgpt_llm: "gpt-3.5-turbo"  
  window_size: 4  
  step: 1  

  ###############################################
  ## Response Generation
  ###############################################
  generation_model: "none"  
  generation_prompt: "none"  
  generation_top_k: 3 

  ###############################################
  ## Metrics
  ###############################################
  save_to_wandb: true
  metrics: "map,ndcg,ndcg_cut.1,ndcg_cut.3,ndcg_cut.5,ndcg_cut.10,P.1,P.3,P.5,P.10,P.20,recall.5,recall.10,recall.20,recall.50,recall.100,recall.1000,recip_rank"  
  metrics_to_print: ["recip_rank", "ndcg_cut_3", "recall_10", "recall_100"]
  given_ranking_list_path: "/data/rech/huiyuche/TREC_iKAT_2024/results/ClueWeb_ikat/ikat_24_test/ranking/S1[gpt-4o_rar_rw_fuse_rar_rwrs_fuse_non_personalized_cot1_rw]-S2[gpt-4o_rar_personalized_cot1_rw]-g[gpt-4o_rar_personalized_cot1_rw]-[none]-[monot5_base_10k_4_1_none]-[s2_top50].txt"  

  ###############################################
  ## iKAT Project Specific
  ###############################################
  run_name: "none"  
  retrieval_query_type: "none"  
  reranking_query_type: "none"  
  generation_query_type: "none"  
