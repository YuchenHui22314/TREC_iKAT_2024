##########################################################
##########################################################
###                                                    ###
###      Config file for runing iKAT experiments       ###
###                                                    ###
##########################################################
##########################################################



###############################################################
##### First zone: Combinations of experiments to run
###############################################################
iterate:
  # modify this to your own machine name after adding
  # the machine_name <==> indexes_paths mapping in the second zone
  machine: ["octal30"] 
  topics: ["ikat_23_test", "ikat_24_test"]
  retrieval_model: ["BM25"]
  retrieval_query_type: [
    ours_low_resource_100"
]
  reranker : ["monot5_base_10k"]


###############################################################
##### Second zone: define some fixed relationships between the parameters
###############################################################
param_mapping:
  machine:
    octal31:
      sparse_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_official_sparse_index/"  # Use local disk index for fastest access
      splade_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_splade_v3"  # Splade index path
      dense_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_ance_merged_2"  
    octal30:
      sparse_index_dir_path: "/part/02/Tmp/yuchen/indexes/clueweb22b_ikat23_official_sparse_index/"  # Use local disk index for fastest access
      splade_index_dir_path: "/part/02/Tmp/yuchen/indexes/clueweb22b_ikat23_splade_v3"  # Splade index path
      dense_index_dir_path: "/part/02/Tmp/yuchen/indexes/clueweb22b_ikat23_ance_merged_2"  

  # this depends on your GPU resources
  reranker:
    monot5_base_10k:
      rerank_batch_size: 67
    monot5_large_10k:
      rerank_batch_size: 50
    monot5_3b_10k:
      rerank_batch_size: 10
    rankllama:
      rerank_batch_size: 10

  topics:
    ikat_24_test:
      input_query_path: "../../data/topics/ikat24/ikat_2024_test.json"
      qrel_file_path: "../../data/qrels/ikat_24_qrel.txt"             # not available for non-participants
    ikat_23_test:
      input_query_path: "../../data/topics/ikat23/ikat_2023_test.json"
      qrel_file_path: "../../data/qrels/ikat_23_qrel.txt"

  retrieval_query_type:
    MQ4CS_low_resource:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_1, 
        gpt-4o_MQ4CS_mq_2
        ]
      personalization_group: "all"
      retrieval_top_k: 2000
      rerank_top_k: 2000
      reranking_query_type: "gpt-4o_MQ4CS_persq_rw"
      fusion_type: 'concat'
      reranker: "monot5_base_10k"

    gpt-4o_judge_and_rewrite_optimize_retrieval_score:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "retrieval_score"

    gpt-4o_GtR_low_resource_3_Round_Robin:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      fusion_type: 'round_robin'

    gpt-4o_GtR_low_resource_3_grid_search:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      fusion_type: 'per_query_personalize_level'
      optimize_level_weights: "no_level" 

    gpt-4o_GtR_low_resource_3_RRF:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      fusion_type: 'RRF'

    gpt-4o_GtR_low_resource_3:
      QRs_to_rank: [
        "gpt-4o_GtR_mq_3_1",
        "gpt-4o_GtR_mq_3_2",
        "gpt-4o_GtR_mq_3_3",
        ]
      personalization_group: "all"
      retrieval_top_k: 3000
      rerank_top_k: 3000
      reranking_query_type: "gpt-4o_MQ4CS_persq_rw"
      fusion_type: 'round_robin'
      reranker: "monot5_base_10k"

    MQ4CS_low_resource_3_Round_Robin:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      fusion_type: 'round_robin'

    MQ4CS_low_resource_3_RRF:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      fusion_type: 'RRF'

    MQ4CS_low_resource_3_grid_search:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      fusion_type: 'per_query_personalize_level'
      optimize_level_weights: "no_level" 

    MQ4CS_low_resource_3:
      QRs_to_rank: [
        gpt-4o_MQ4CS_mq_3_1, 
        gpt-4o_MQ4CS_mq_3_2,
        gpt-4o_MQ4CS_mq_3_3
        ]
      personalization_group: "all"
      retrieval_top_k: 3000
      rerank_top_k: 3000
      reranking_query_type: "gpt-4o_MQ4CS_persq_rw"
      fusion_type: 'concat'
      reranker: "monot5_base_10k"

    ours_low_resource:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 1000
      rerank_top_k: 50
      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    ours_low_resource_100:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 1000
      rerank_top_k: 100
      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    ours_low_resource_rerank2000:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 2000
      rerank_top_k: 2000

      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    ours_low_resource_rerank1000:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_judge_and_rewrite_rw
        ]
      personalization_group: "all"
      retrieval_top_k: 1000
      rerank_top_k: 1000

      reranking_query_type: gpt-4o_judge_and_rewrite_rw

      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_depers_jar_optimize_4:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_depers_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw_optimize_4:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_rar_manual_depersonalized_cot1_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_rar_manual_depersonalized_cot1_rw
        ]

      fusion_type: 'linear_weighted_score'
      fuse_weights: [0.1, 0.4]
      retrieval_model: "BM25"

    wo_cot:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_jtr_wo_cot_rw
        ]
      level_type: "gpt-4o_jtr_wo_cot" 
      fusion_type: 'per_query_personalize_level'
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    wo_in_context:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_jtr_wo_in_context_rw
        ]
      level_type: "gpt-4o_jtr_wo_in_context" 
      fusion_type: 'per_query_personalize_level'
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    wo_explicit_level:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'per_query_personalize_level'
      optimize_level_weights: "no_level" 
      fusion_normalization: "min-max"

    wo_finegrianed:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'linear_combination'
      fusion_normalization: "min-max"
      fuse_weights: [1,1,1]

    gpt-4o_judge_and_rewrite_optimize_4_test_no_normalize:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "none"
      optimize_level_weights: "group" 

    gpt-4o_judge_and_rewrite_optimize_4_test:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      # while runing reranking with existing 1st stage retrieval,
      # should set the fusion type to "none"
      fusion_type: 'none'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    RRF_3_lists:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'RRF'

    round_robin_3_lists:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'round_robin'

    2024_submission:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs,
        gpt-4o_rar_personalized_cot1_rw
        ]
      fusion_type: 'linear_weighted_score'
      fuse_weights: [0.1, 0.4]
      retrieval_model: "BM25"

    mistral_judge_and_rewrite_optimize_4_test : 
      QRs_to_rank: [
        mistral_rar_rw, 
        mistral_rar_rwrs, 
        mistral_judge_and_rewrite_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "mistral_judge_and_rewrite"
    llama3.1_judge_and_rewrite_optimize_4_test : 
      QRs_to_rank: [
        llama3.1_rar_rw, 
        llama3.1_rar_rwrs, 
        llama3.1_judge_and_rewrite_rw
      ]
      fusion_type: 'per_query_personalize_level'
      level_type: "llama3.1_judge_and_rewrite"
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.4]
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [1, 0.1]
    gpt-4o_rar_rw_fuse_rar_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs]
      fuse_weights: [1, 0.1]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [0.1, 0.4]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [0.1, 0.1]
    gpt-4o_judge_and_rewrite_rw_fuse_rwrs:
      QRs_to_rank: [gpt-4o_judge_and_rewrite_rw, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [0.4, 0.1]
    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.1, 0.4]
    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [1, 0.1, 0.1]
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.1, 0.4]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [0.1, 0.1, 0.4] 
    


###############################################################
##### Third zone: All other parameters that should remaining unchanged for all the exmperiments defined in the first zone.
###############################################################

fixed:

  ###############################################
  ## General
  ###############################################
  collection: "ClueWeb_ikat"  # Dataset collection
  topics: "ikat_23_test"  # Test topics
  input_query_path: "../../data/topics/ikat23/ikat_2023_test.json"  # Path to input query file
  sparse_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_official_sparse_index/"  # Use local disk index for fastest access
  output_dir_path: "../../results"  # Path to save results
  qrel_file_path: "../../data/qrels/ikat_23_qrel.txt"  # Qrel file path
  seed: 42  # Random seed for reproducibility

  save_results_to_object: true
  save_ranking_list: true
  run_rag: true
  run_eval: true

  ###############################################
  ## Retrieval
  ###############################################
  # can be :"none","BM25", "ance", "dpr", "splade_v3". If "none", read ranking list from given_ranking_list_path
  retrieval_model: "ance"  
  retrieval_top_k: 1000  
  # "a" "b" "c" "all"
  personalization_group: "all"
  query_gpu_id: 2  # GPU ID for query encoder
  query_encoder_batch_size: 200  # Batch size for query encoding

  ############# Splade ############
  splade_query_encoder_path: "your splade path"  # Splade query encoder path
  splade_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_splade_v3"  # Splade index path

  ############# Dense  ############
  use_pyserini_dense_search: false
  dense_query_encoder_path: "your dense path"  # Dense query encoder path
  dense_index_dir_path: "your dense index path"  # Dense index path
  faiss_n_gpu: 4  # Number of GPUs for FAISS
  use_gpu_for_faiss: true
  embed_dim: 768  # Embedding dimension
  tempmem: -1  # Temporary memory setting
  passage_block_num: 12  # 116 for ikat

  ############# BM25 ############
  bm25_k1: 0.9  
  bm25_b: 0.4  

  ############# QE ############
  qe_type: "none"  
  fb_terms: 20  
  fb_docs: 10  
  original_query_weight: 0.5  

  ###############################################
  ## Fusion
  ###############################################
  #'none' 'round_robin', 'lienar_combination' 'linear_weighted_score' 'per_query_personalize_level'
  fusion_type: 'none'  
  #QRs_to_rank: ["gpt-4o_rar_rw", "gpt-4o_rar_rwrs", "gpt-4o_rar_personalized_cot1_rw"]
  QRs_to_rank: [
    "mistral_rar_rw", 
    "mistral_rar_rwrs",
    "mistral_judge_and_rewrite_rw"
    ]  
  fuse_weights: [0.1, 0.4]  
  # can be "none", "max", "min-max"
  fusion_normalization: "none"  
  # can be 'per_query_personalize_level', "gpt-4o_judge_and_rewrite","gpt-3.5_judge_and_rewrite"
  level_type: "gpt-3.5_judge_and_rewrite"  
  per_query_weight_max_value: 1.2  
  # can be 
  # (1) "no level", means finding the optimal weights for all ranking lists respectively 
  # (2) "2+1": first find the best weight for the 2 non-personalized query, then
  #   for the personalized query, perform optimization by group.
  # (3) "group": optimize by personalization level group
  optimize_level_weights: "group"  
  target_metrics: "mrr,ndcg@3,recall@10,recall@100"  
  optimize_step: 0.01  # Optimization step size

  ###############################################
  ## Reranking
  ###############################################
  # none, rankllama, rankgpt, monot5_base, monot5_base_10k, monot5_large, monot5_large_10k, monot5_3b, monot5_3b_10k,
  reranker: "none"  
  rerank_top_k: 50  
  cache_dir: "huggingface_cache"  
  # on octal31: 67 for monot5_base, 10 for rankllama, 50 for monot5_large, 10 for t5_3b
  rerank_batch_size: 67  
  rerank_quant: "none"   # can be "none" ,"8b", "4b"
  rankgpt_llm: "gpt-3.5-turbo"  
  window_size: 4  
  step: 1  

  ###############################################
  ## Response Generation
  ###############################################
  generation_model: "none"  
  generation_prompt: "none"  
  generation_top_k: 3 

  ###############################################
  ## Metrics
  ###############################################
  save_to_wandb: true
  metrics: "map,ndcg,ndcg_cut.1,ndcg_cut.3,ndcg_cut.5,ndcg_cut.10,P.1,P.3,P.5,P.10,P.20,recall.5,recall.10,recall.20,recall.50,recall.100,recall.1000,recip_rank"  
  metrics_to_print: ["recip_rank", "ndcg_cut_3", "recall_10", "recall_100"]
  given_ranking_list_path: "../../results/ClueWeb_ikat/ikat_24_test/ranking/S1[gpt-4o_rar_rw_fuse_rar_rwrs_fuse_non_personalized_cot1_rw]-S2[gpt-4o_rar_personalized_cot1_rw]-g[gpt-4o_rar_personalized_cot1_rw]-[none]-[monot5_base_10k_4_1_none]-[s2_top50].txt"  

  ###############################################
  ## iKAT Project Specific
  ###############################################
  run_name: "none"  
  retrieval_query_type: "none"  
  reranking_query_type: "none"  
  generation_query_type: "none"  
