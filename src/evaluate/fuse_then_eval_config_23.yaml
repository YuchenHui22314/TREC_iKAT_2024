##########################################################
##########################################################
###                                                    ###
###      Config file for runing iKAT experiments       ###
###                                                    ###
##########################################################
##########################################################

iterate:

# rewrites choices
  # P -> personalize, D -> demo, C -> cot, Re -> rel explain
  # O -> oracle, Rf -> rel feedback

  #retrieval_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs")
  #reranking_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___")
  #reranking_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___")
  #reranking_query_types=("rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rwrs" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___")
  # reranking_query_types=("rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rwrs")
  #retrieval_query_types=("raw" "rar_rw" "rar_rwrs" "oracle_utterance" "raw_llm_rm_P__Re___" "raw_llm_rm____Re___" "rar_ptkb_sum_cot0_rw" "rar_ptkb_sum_cot0_rwrs" "rar_ptkb_sum_rw" "rar_ptkb_sum_rwrs")
  #retrieval_query_types=("rar_personalized_cot1_rw" "rar_personalized_cotN_rw")
  #retrieval_query_types=("rar_rw_fuse_rar_personcot1_rw")
  # retrieval_query_types=("rar_rw_fuse_rar_rwrs")
  # reranking_query_types=("rar_personalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_rar_rw" "gpt-4o_rar_rwrs" "gpt-4o_rar_personalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_rar_rw_fuse_rar_rwrs_fuse_manual_depersonalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_rar_rwrs_fuse_personalized_cot1_rw") 
  #retrieval_query_types=("round_robin_gpt-4o_3_lists")
  #retrieval_query_types=("personalize_level_3_lists_tune") 
  #retrieval_query_types=("gpt-4o_rar_rw" "gpt-4o_rar_rwrs" "gpt-4o_rar_personalized_cot1_rw")
  #retrieval_query_types=("gpt-4o_judge_and_rewrite_optimize_mrr_non_normalize_test")
  #retrieval_query_type: ["gpt-4o_judge_and_rewrite_rwrs","gpt-4o_judge_and_rewrite_rs", "gpt-4o_rar_personalized_cot1_rs","gpt-4o_rar_personalized_cot1_rwrs", "gpt-4o_rar_rs" ]

  #retrieval_query_type: ["raw", "oracle"]
  #retrieval_query_type: ["gpt-4o_judge_and_rewrite_optimize_4_test"]
  # retrieval_query_type: [ "gpt-3.5_judge_and_rewrite_optimize_4_test"] 
  # retrieval_query_type: [
  #   "mistral_rar_rw",
  #   "mistral_rar_rwrs",
  #   "mistral_judge_and_rewrite_rw",
  #   "mistral_judge_and_rewrite_rwrs",
  #   "llama3.1_judge_and_rewrite_rw",
  #   "llama3.1_judge_and_rewrite_rwrs",
  #   "llama3.1_rar_rw",
  #   "llama3.1_rar_rwrs"
  # ]

  # topics: ["ikat_23_test","ikat_24_test"]
  # retrieval_query_type: [ 
  #   mistral_judge_and_rewrite_optimize_4_test,
  #   llama3.1_judge_and_rewrite_optimize_4_test,
  #   gpt-3.5_judge_and_rewrite_optimize_4_test,
  #   gpt-4o_judge_and_rewrite_optimize_4_test
  #   ] 
  # retrieval_model: ["splade_v3"] 
  # reranker: [none]
  # reranking_query_type: ["none"]
  
  # topics: ["ikat_23_test","ikat_24_test"]
  # retrieval_query_type: [ 
  #   oracle
  #   ] 
  # retrieval_model: ["splade_v3"] 
  # reranker: ["monot5_base_10k"]
  # reranking_query_type: ["oracle"]
  # fusion_type: ['none']

  # topics: ["ikat_24_test"]
  # retrieval_query_type: [ 
  #   "round_robin_3_lists",
  #   "gpt-4o_rar_rw+gpt-4o_rar_rwrs+gpt-4o_judge_and_rewrite_rw",
  #   "RRF_3_lists"
  #   ] 
  # retrieval_model: ["splade_v3"]
  # reranker: ["none"]
  # reranking_query_type: ["none"]

  topics: ["ikat_24_test", "ikat_24_test"]
  retrieval_query_type: [ 
    gpt-4o_judge_and_rewrite_optimize_4_test_no_normalize
    ] 
  retrieval_model: ["splade_v3"]
  reranker: ["none"]
  reranking_query_type: ["none"]
param_mapping:

  reranker:
    monot5_base_10k:
      rerank_batch_size: 67
    monot5_large_10k:
      rerank_batch_size: 50
    monot5_3b_10k:
      rerank_batch_size: 10
    rankllama:
      rerank_batch_size: 10

  topics:
    ikat_24_test:
      input_query_path: "../../data/topics/ikat24/ikat_2024_test.json"
      qrel_file_path: "../../data/qrels/ikat_24_qrel.txt"
    ikat_23_test:
      input_query_path: "../../data/topics/ikat23/ikat_2023_test.json"
      qrel_file_path: "../../data/qrels/ikat_23_qrel.txt"

  retrieval_query_type:

    gpt-4o_judge_and_rewrite_optimize_4_test_no_normalize:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "none"
      optimize_level_weights: "group" 

    gpt-4o_judge_and_rewrite_optimize_4_test:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "gpt-4o_judge_and_rewrite"
      fusion_normalization: "min-max"
      optimize_level_weights: "group" 

    RRF_3_lists:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'RRF'

    round_robin_3_lists:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs, 
        gpt-4o_judge_and_rewrite_rw
        ]
      fusion_type: 'round_robin'

    2024_submission:
      QRs_to_rank: [
        gpt-4o_rar_rw, 
        gpt-4o_rar_rwrs,
        gpt-4o_rar_personalized_cot1_rw
        ]
      fusion_type: 'linear_weighted_score'
      fuse_weights: [0.1, 0.4]
      retrieval_model: "BM25"

    mistral_judge_and_rewrite_optimize_4_test : 
      QRs_to_rank: [
        mistral_rar_rw, 
        mistral_rar_rwrs, 
        mistral_judge_and_rewrite_rw
        ]
      fusion_type: 'per_query_personalize_level'
      level_type: "mistral_judge_and_rewrite"
    llama3.1_judge_and_rewrite_optimize_4_test : 
      QRs_to_rank: [
        llama3.1_rar_rw, 
        llama3.1_rar_rwrs, 
        llama3.1_judge_and_rewrite_rw
      ]
      fusion_type: 'per_query_personalize_level'
      level_type: "llama3.1_judge_and_rewrite"
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.4]
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [1, 0.1]
    gpt-4o_rar_rw_fuse_rar_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs]
      fuse_weights: [1, 0.1]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [0.1, 0.4]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [0.1, 0.1]
    gpt-4o_judge_and_rewrite_rw_fuse_rwrs:
      QRs_to_rank: [gpt-4o_judge_and_rewrite_rw, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [0.4, 0.1]
    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.1, 0.4]
    gpt-4o_rar_rw_fuse_rar_rwrs_fuse_judge_and_rewrite_rwrs:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs]
      fuse_weights: [1, 0.1, 0.1]
    gpt-4o_rar_rw_fuse_judge_and_rewrite_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rw, gpt-4o_judge_and_rewrite_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [1, 0.1, 0.4]
    gpt-4o_rar_rwrs_fuse_judge_and_rewrite_rwrs_fuse_judge_and_rewrite_rw:
      QRs_to_rank: [gpt-4o_rar_rwrs, gpt-4o_judge_and_rewrite_rwrs, gpt-4o_judge_and_rewrite_rw]
      fuse_weights: [0.1, 0.1, 0.4] 
    

fixed:
  ###############################################
  ## General
  ###############################################
  collection: "ClueWeb_ikat"  # Dataset collection
  topics: "ikat_23_test"  # Test topics
  input_query_path: "../../data/topics/ikat23/ikat_2023_test.json"  # Path to input query file

  # use /part/02 for octal30, /part/01 for octal31
  # index_dir_path="/part/02/Tmp/yuchen/clueweb22b_ikat23_fengran_sparse_index_2/" # Please use local disk index to achieve the fastest access
  sparse_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_official_sparse_index/"  # Use local disk index for fastest access
  output_dir_path: "../../results"  # Path to save results
  qrel_file_path: "../../data/qrels/ikat_23_qrel.txt"  # Qrel file path
  seed: 42  # Random seed for reproducibility

  save_results_to_object: true
  save_ranking_list: true
  run_rag: true
  run_eval: true

  ###############################################
  ## Retrieval
  ###############################################
  # can be :"none","BM25", "ance", "dpr", "splade_v3". If "none", read ranking list from given_ranking_list_path
  retrieval_model: "ance"  
  retrieval_top_k: 1000  
  query_gpu_id: 2  # GPU ID for query encoder
  query_encoder_batch_size: 200  # Batch size for query encoding

  ############# Splade ############
  splade_query_encoder_path: "/data/rech/huiyuche/huggingface/models--naver--splade-v3/snapshots/8291b13eb8f4e24cc745c542825f14eb87296879"  # Splade query encoder path
  splade_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_splade_v3"  # Splade index path

  ############# Dense  ############
  use_pyserini_dense_search: false
  dense_query_encoder_path: "/data/rech/huiyuche/huggingface/models--castorini--ance-msmarco-passage/snapshots/6d7e7d6b6c59dd691671f280bc74edb4297f8234"  
  dense_index_dir_path: "/part/01/Tmp/yuchen/indexes/clueweb22b_ikat23_ance_merged_2"  
  faiss_n_gpu: 4  # Number of GPUs for FAISS
  use_gpu_for_faiss: true
  embed_dim: 768  # Embedding dimension
  tempmem: -1  # Temporary memory setting
  passage_block_num: 12  # 116 for ikat

  ############# BM25 ############
  bm25_k1: 0.9  
  bm25_b: 0.4  

  ############# QE ############
  qe_type: "none"  
  fb_terms: 20  
  fb_docs: 10  
  original_query_weight: 0.5  

  ###############################################
  ## Fusion
  ###############################################
  #'none' 'round_robin', 'lienar_combination' 'linear_weighted_score' 'per_query_personalize_level'
  fusion_type: 'none'  
  #QRs_to_rank: ["gpt-4o_rar_rw", "gpt-4o_rar_rwrs", "gpt-4o_rar_personalized_cot1_rw"]
  QRs_to_rank: [
    "mistral_rar_rw", 
    "mistral_rar_rwrs",
    "mistral_judge_and_rewrite_rw"
    ]  
  fuse_weights: [0.1, 0.4]  
  # can be "none", "max", "min-max"
  fusion_normalization: "none"  
  # can be 'per_query_personalize_level', "gpt-4o_judge_and_rewrite","gpt-3.5_judge_and_rewrite"
  level_type: "gpt-3.5_judge_and_rewrite"  
  per_query_weight_max_value: 1.2  
  # can be 
  # (1) "no level", means finding the optimal weights for all ranking lists respectively 
  # (2) "2+1": first find the best weight for the 2 non-personalized query, then
  #   for the personalized query, perform optimization by group.
  # (3) "group": optimize by personalization level group
  optimize_level_weights: "group"  
  target_metrics: "mrr,ndcg@3,recall@10,recall@100"  
  optimize_step: 0.01  # Optimization step size

  ###############################################
  ## Reranking
  ###############################################
  # none, rankllama, rankgpt, monot5_base, monot5_base_10k, monot5_large, monot5_large_10k, monot5_3b, monot5_3b_10k,
  reranker: "none"  
  rerank_top_k: 50  
  cache_dir: "/data/rech/huiyuche/huggingface"  
  # on octal31: 67 for monot5_base, 10 for rankllama, 50 for monot5_large, 10 for t5_3b
  rerank_batch_size: 67  
  rerank_quant: "none"   # can be "none" ,"8b", "4b"
  rankgpt_llm: "gpt-3.5-turbo"  
  window_size: 4  
  step: 1  

  ###############################################
  ## Response Generation
  ###############################################
  generation_model: "none"  
  generation_prompt: "none"  
  generation_top_k: 3 

  ###############################################
  ## Metrics
  ###############################################
  save_to_wandb: true
  metrics: "map,ndcg,ndcg_cut.1,ndcg_cut.3,ndcg_cut.5,ndcg_cut.10,P.1,P.3,P.5,P.10,P.20,recall.5,recall.10,recall.20,recall.50,recall.100,recall.1000,recip_rank"  
  metrics_to_print: ["recip_rank", "ndcg_cut_3", "recall_10", "recall_100"]
  given_ranking_list_path: "/data/rech/huiyuche/TREC_iKAT_2024/results/ClueWeb_ikat/ikat_24_test/ranking/S1[gpt-4o_rar_rw_fuse_rar_rwrs_fuse_non_personalized_cot1_rw]-S2[gpt-4o_rar_personalized_cot1_rw]-g[gpt-4o_rar_personalized_cot1_rw]-[none]-[monot5_base_10k_4_1_none]-[s2_top50].txt"  

  ###############################################
  ## iKAT Project Specific
  ###############################################
  run_name: "none"  
  retrieval_query_type: "none"  
  reranking_query_type: "none"  
  generation_query_type: "none"  
